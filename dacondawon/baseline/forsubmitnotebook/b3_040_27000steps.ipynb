{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' # nvidia-smi로 비어있는 gpu 확인하고 여기서 선택할것!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leadawon5/dawon/visionvenv/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "#import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output \n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 디코딩 함수\n",
    "def rle_decode(mask_rle, shape):\n",
    "    if mask_rle == -1:\n",
    "        return np.zeros(shape, dtype=np.uint8)\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "def is_number_in_list(lst, target):\n",
    "    index = bisect.bisect_left(lst, target)\n",
    "    if index != len(lst) and lst[index] == target:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class split_stride:\n",
    "    def __init__(self, csv_file, image_dir='../split_data_stride_160', stride=160):\n",
    "        self.csv_file = csv_file\n",
    "        self.stride = stride\n",
    "        self.size = 224\n",
    "        self.image_dir = image_dir\n",
    "        with open(\"./train_trash.json\",\"r\") as js:\n",
    "            json_file = json.load(js)\n",
    "        \n",
    "        train_trash = json_file[\"must\"]\n",
    "        train_quarter = json_file[\"quarter\"]\n",
    "\n",
    "        with open(\"./val_trash.json\",\"r\") as js:\n",
    "            json_file = json.load(js)\n",
    "\n",
    "        val_trash = json_file[\"must\"]\n",
    "        val_quarter = json_file[\"quarter\"]\n",
    "\n",
    "        trash_sum_list = train_trash + train_quarter + val_trash + val_quarter\n",
    "\n",
    "        self.strong_filter_list = sorted(trash_sum_list)\n",
    "        self.data = pd.read_csv(self.csv_file)\n",
    "        self.splitlen = len(self.data) * (int(800 / stride + 1) ** 2)\n",
    "        self.img_id = []\n",
    "        self.img_path = []\n",
    "        self.masks = []\n",
    "        \n",
    "        self.save_split_images()\n",
    "        \n",
    "        # CSV\n",
    "        self.data = pd.DataFrame()\n",
    "        self.data['img_id'] = self.img_id\n",
    "        self.data['img_path'] = self.img_path\n",
    "        for i in tqdm(range(len(self.data))):\n",
    "            if self.masks[i]=='':\n",
    "                self.masks[i]=-1\n",
    "        self.data['mask_rle'] = self.masks\n",
    "        self.data.to_csv('../data/jhs_stride_160.csv', index=False)\n",
    "        print(\"CSV 작성 완료!\")\n",
    "    \n",
    "    def save_split_images(self):\n",
    "        count = 0\n",
    "        for i in tqdm(range(len(self.data))):\n",
    "            if is_number_in_list(self.strong_filter_list, i):\n",
    "                continue\n",
    "            image_path = \"../data\" + self.data.iloc[i, 1][1:]\n",
    "            image = cv2.imread(image_path)\n",
    "            mask = rle_decode(self.data.iloc[i, 2], (image.shape[0], image.shape[1]))\n",
    "            \n",
    "            img_height, img_width = image.shape[0], image.shape[1]\n",
    "            \n",
    "            for top in range(0, img_height, self.stride):\n",
    "                if top + self.size > img_height:\n",
    "                    break\n",
    "                for left in range(0, img_width, self.stride):\n",
    "                    if left + self.size > img_width:\n",
    "                        break\n",
    "                    bottom = top + self.size\n",
    "                    right = left + self.size\n",
    "                    \n",
    "                    img_patch = image[top:bottom, left:right]\n",
    "                    mask_patch = mask[top:bottom, left:right]\n",
    "                    \n",
    "                    text = str(count).zfill(8)\n",
    "                    img_id = f'TRAIN_{text}'\n",
    "\n",
    "                    cv2.imwrite(f'../split_data_stride_160/TRAIN_{text}.png', img_patch)\n",
    "                    \n",
    "                    self.img_id.append(img_id)\n",
    "                    self.img_path.append(f'./split_data_stride_160/TRAIN_{text}.png')\n",
    "                 \n",
    "                    self.masks.append(rle_encode(mask_patch))\n",
    "                    \n",
    "                    count += 1\n",
    "csv = split_stride(csv_file='../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.data.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nvidia/mit-b3 were not used when initializing SegformerForSemanticSegmentation: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b3 and are newly initialized: ['decode_head.batch_norm.running_var', 'decode_head.linear_c.0.proj.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.weight', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.3.proj.weight', 'decode_head.classifier.weight', 'decode_head.batch_norm.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.batch_norm.running_mean', 'decode_head.linear_c.2.proj.bias', 'decode_head.classifier.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_fuse.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "id2label = {1:'building'}\n",
    "label2id = {'building':1}\n",
    "pretrained_model_name = \"nvidia/mit-b3\"\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    pretrained_model_name,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "        \n",
    "        print(\"full dataset size : \",len(self.data))\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = \"../data\"+self.data.iloc[idx, 1][1:]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "                dic = {\"pixel_values\":image}\n",
    "\n",
    "            return dic\n",
    "        assert False , \"SatelliteDataset class must be used as test dataset obj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TV_SatelliteDataset(Dataset):\n",
    "    def __init__(self, csv_file=\"../data/jhs_stride_160.csv\", transform=None, is_train = True, stride=200):\n",
    "        self.is_train = is_train\n",
    "        self.transform = transform\n",
    "        self.stride = stride\n",
    "        self.size = 224\n",
    "        self.cutter = int(241920*0.8) #tv cutter\n",
    "        \n",
    "        if self.is_train:\n",
    "            self.data = pd.read_csv(csv_file)[:self.cutter]\n",
    "        else:\n",
    "            self.data = pd.read_csv(csv_file)[self.cutter:]\n",
    "\n",
    "\n",
    "        \n",
    "        print(\"Full dataset size:\", len(self.data))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        augmented = self.transform(image=cv2.cvtColor(cv2.imread(\"..\"+self.data.iloc[idx, 1][1:]), cv2.COLOR_BGR2RGB), mask=rle_decode(self.data.iloc[idx, 2], (224, 224)))\n",
    "        return {\"pixel_values\":augmented['image'],\"labels\":augmented['mask'].type(torch.LongTensor)}\n",
    "        \n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset size: 193536\n",
      "Full dataset size: 193536\n",
      "Full dataset size: 193536\n",
      "Full dataset size: 193536\n",
      "Full dataset size: 193536\n",
      "Full dataset size: 48384\n",
      "full dataset size :  60640\n"
     ]
    }
   ],
   "source": [
    "aug1 = A.Compose(\n",
    "    [   \n",
    "        #A.Resize(512, 512),\n",
    "        A.OneOf([\n",
    "            A.CLAHE(p = 0.1),\n",
    "            A.RandomBrightnessContrast(contrast_limit=0.1, brightness_by_max=False),\n",
    "            A.GaussNoise(var_limit=(0.0, 25.0), p = 0.1)\n",
    "        ]),\n",
    "\n",
    "        # A.RandomCrop(width=224, height=224, p = 0.1),\n",
    "\n",
    "        A.Affine(shear=(-10, 10)),\n",
    "\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "aug2 = A.Compose(\n",
    "    [   \n",
    "        #A.Resize(512, 512),\n",
    "        \n",
    "        A.VerticalFlip(),\n",
    "        \n",
    "\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "aug3 = A.Compose(\n",
    "    [   \n",
    "        #A.Resize(512, 512),\n",
    "        \n",
    "        A.HorizontalFlip(),\n",
    "\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "aug4 = A.Compose(\n",
    "    [   \n",
    "        #A.Resize(512, 512),\n",
    "        \n",
    "        A.Rotate(),\n",
    "\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform = A.Compose(\n",
    "    [   \n",
    "        #A.Resize(512, 512),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "aug1_dataset = TV_SatelliteDataset(transform=aug1, is_train=True)\n",
    "aug2_dataset = TV_SatelliteDataset(transform=aug2, is_train=True)\n",
    "aug3_dataset = TV_SatelliteDataset(transform=aug3, is_train=True)\n",
    "aug4_dataset = TV_SatelliteDataset(transform=aug4, is_train=True)\n",
    "train_ds = TV_SatelliteDataset(transform=transform, is_train=True)\n",
    "\n",
    "train_ds = ConcatDataset([train_ds,aug1_dataset,aug2_dataset,aug3_dataset,aug4_dataset])\n",
    "val_ds = TV_SatelliteDataset(transform=transform, is_train=False)\n",
    "\n",
    "\n",
    "test_ds = SatelliteDataset(csv_file='../data/test.csv', transform=transform, infer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## huggingface cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "epochs = 4\n",
    "lr = 0.00006\n",
    "batch_size = 64\n",
    "\n",
    "hub_model_id = \"segformer-b3\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"segformer-b3\",\n",
    "    learning_rate=lr,\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    save_total_limit=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=3000,\n",
    "    eval_steps=3000,\n",
    "    logging_steps=1,\n",
    "    eval_accumulation_steps=5,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=hub_model_id,\n",
    "    hub_strategy=\"end\",\n",
    "    seed=random_seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/leadawon/segformer-b3 into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    #compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leadawon5/dawon/visionvenv/lib/python3.7/site-packages/transformers/optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30365' max='60480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30365/60480 32:21:50 < 32:05:58, 0.26 it/s, Epoch 2.01/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.045847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.042512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.040026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.039431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.039138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.039382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.038783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.038280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.037817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.038446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3566/1052710176.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#trainer.train(resume_from_checkpoint = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dawon/visionvenv/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m         )\n\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dawon/visionvenv/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrng_to_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dawon/visionvenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dawon/visionvenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dawon/visionvenv/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dawon/visionvenv/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dawon/visionvenv/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3566/3072470790.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0maugmented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"..\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrle_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"pixel_values\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maugmented\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maugmented\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#trainer.train(resume_from_checkpoint = True)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_ds, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    \"./segformer-b3/checkpoint-27000\",\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegformerForSemanticSegmentation(\n",
       "  (segformer): SegformerModel(\n",
       "    (encoder): SegformerEncoder(\n",
       "      (patch_embeddings): ModuleList(\n",
       "        (0): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (block): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.003703703870996833)\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.007407407741993666)\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.011111111380159855)\n",
       "            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.014814815483987331)\n",
       "            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.018518518656492233)\n",
       "            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.02222222276031971)\n",
       "            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.025925926864147186)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.029629630967974663)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.03333333507180214)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.03703703731298447)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.04074074327945709)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.04444444552063942)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.04814814776182175)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.05185185372829437)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.055555559694767)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.05925925821065903)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.06296296417713165)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.06666667014360428)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (12): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.07037036865949631)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (13): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.07407407462596893)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (14): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.07777778059244156)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (15): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.08148147910833359)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (16): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.08518518507480621)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (17): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.08888889104127884)\n",
       "            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.09259259700775146)\n",
       "            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.0962962955236435)\n",
       "            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.10000000149011612)\n",
       "            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): ModuleList(\n",
       "        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decode_head): SegformerDecodeHead(\n",
       "    (linear_c): ModuleList(\n",
       "      (0): SegformerMLP(\n",
       "        (proj): Linear(in_features=64, out_features=768, bias=True)\n",
       "      )\n",
       "      (1): SegformerMLP(\n",
       "        (proj): Linear(in_features=128, out_features=768, bias=True)\n",
       "      )\n",
       "      (2): SegformerMLP(\n",
       "        (proj): Linear(in_features=320, out_features=768, bias=True)\n",
       "      )\n",
       "      (3): SegformerMLP(\n",
       "        (proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (linear_fuse): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Conv2d(768, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████▊                     | 1736/3790 [02:52<03:58,  8.60it/s]"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    result = []\n",
    "    for images in tqdm(test_dataloader):\n",
    "        images = images[\"pixel_values\"].float().to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "                logits,\n",
    "                size=(224,224), # (height, width)\n",
    "                mode='bilinear',\n",
    "                align_corners=False\n",
    "                )\n",
    "\n",
    "        # Second, apply argmax on the class dimension\n",
    "\n",
    "        masks = torch.sigmoid(upsampled_logits).cpu().numpy()\n",
    "        masks = (masks > 0.40).astype(np.uint8) # Threshold = 0.35\n",
    "        for i in range(len(images)):\n",
    "            mask_rle = rle_encode(masks[i][0])\n",
    "            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n",
    "                result.append(-1)\n",
    "            else:\n",
    "                result.append(mask_rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "submit['mask_rle'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('../submit/b3_040_27000steps.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visionvenv",
   "language": "python",
   "name": "visionvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
