{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # nvidia-smi로 비어있는 gpu 확인하고 여기서 선택할것!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leadawon5/dawon/visionvenv/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output \n",
    "import time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 디코딩 함수\n",
    "def rle_decode(mask_rle, shape):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "        print(\"full dataset size : \",len(self.data))\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #img_path = self.data.iloc[idx, 1]    # default : ./train_img/TRAIN_0000.png\n",
    "        img_path = \"../data\"+self.data.iloc[idx, 1][1:]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "\n",
    "        # mask_rle = self.data.iloc[idx, 2]\n",
    "        # mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n",
    "\n",
    "        # if self.transform:\n",
    "        #     augmented = self.transform(image=image, mask=mask)\n",
    "        #     image = augmented['image']\n",
    "        #     mask = augmented['mask']\n",
    "\n",
    "        # return image, mask\n",
    "        assert False , \"SatelliteDataset class must be used as test dataset obj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TV_SatelliteDataset(Dataset):\n",
    "    def __init__(self,transform=None, is_train = True):\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return 114240-11424  ###### 조심할것.\n",
    "        return 11424\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #img_path = self.data.iloc[idx, 1]    # default : ./train_img/TRAIN_0000.png\n",
    "        if not self.is_train:\n",
    "            idx += 102816\n",
    "        img_path = \"../split_data_224/train_img\"+f\"/{idx//16}_{idx%16}.png\"\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        mask_path = \"../split_data_224/train_mask\"+f\"/{idx//16}_{idx%16}.png\"\n",
    "        mask = cv2.imread(mask_path)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #print(\"hello\" , mask.shape)\n",
    "\n",
    "        \n",
    "        #print(\"hello\" , mask.shape)\n",
    "\n",
    "        \n",
    "        #assert fsize != lsize , f\"{fsize} should be different from {lsize}\"\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [   \n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = TV_SatelliteDataset(transform=transform, is_train=True)\n",
    "val_dataset = TV_SatelliteDataset(transform=transform, is_train=False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef1df8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def printdataset(dataset,idx = 0):\n",
    "    clear_output()\n",
    "    sample = dataset[idx]\n",
    "    image, mask = sample\n",
    "    print(type(image))\n",
    "# 이미지와 마스크 시각화\n",
    "    plt.subplot(1, 2, 1)\n",
    "    image = image.permute(1, 2, 0)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"image\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.title(\"mask\")\n",
    "    plt.show()\n",
    "    #print(len(image),len(image[0]), len(mask), len(mask[0]))\n",
    "    #print(mask.shape)\n",
    "    #print(image.shape)\n",
    "    time.sleep(1)\n",
    "for i in range(4):\n",
    "    printdataset(train_dataset, i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "    \n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "        self.down_sample = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_out = self.double_conv(x)\n",
    "        down_out = self.down_sample(skip_out)\n",
    "        return (down_out, skip_out)\n",
    "\n",
    "    \n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, up_sample_mode):\n",
    "        super(UpBlock, self).__init__()\n",
    "        if up_sample_mode == 'conv_transpose':\n",
    "            self.up_sample = nn.ConvTranspose2d(in_channels-out_channels, in_channels-out_channels, kernel_size=2, stride=2)        \n",
    "        elif up_sample_mode == 'bilinear':\n",
    "            self.up_sample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported `up_sample_mode` (can take one of `conv_transpose` or `bilinear`)\")\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, down_input, skip_input):\n",
    "        x = self.up_sample(down_input)\n",
    "        x = torch.cat([x, skip_input], dim=1)\n",
    "        return self.double_conv(x)\n",
    "\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, out_classes=1, up_sample_mode='conv_transpose'): # out_class 1???\n",
    "        super(UNet, self).__init__()\n",
    "        self.up_sample_mode = up_sample_mode\n",
    "        # Downsampling Path\n",
    "        self.down_conv1 = DownBlock(3, 64)\n",
    "        self.down_conv2 = DownBlock(64, 128)\n",
    "        self.down_conv3 = DownBlock(128, 256)\n",
    "        self.down_conv4 = DownBlock(256, 512)\n",
    "        # Bottleneck\n",
    "        self.double_conv = DoubleConv(512, 1024)\n",
    "        # Upsampling Path\n",
    "        self.up_conv4 = UpBlock(512 + 1024, 512, self.up_sample_mode)\n",
    "        self.up_conv3 = UpBlock(256 + 512, 256, self.up_sample_mode)\n",
    "        self.up_conv2 = UpBlock(128 + 256, 128, self.up_sample_mode)\n",
    "        self.up_conv1 = UpBlock(128 + 64, 64, self.up_sample_mode)\n",
    "        # Final Convolution\n",
    "        self.conv_last = nn.Conv2d(64, out_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, skip1_out = self.down_conv1(x)\n",
    "        x, skip2_out = self.down_conv2(x)\n",
    "        x, skip3_out = self.down_conv3(x)\n",
    "        x, skip4_out = self.down_conv4(x)\n",
    "        x = self.double_conv(x)\n",
    "        x = self.up_conv4(x, skip4_out)\n",
    "        x = self.up_conv3(x, skip3_out)\n",
    "        x = self.up_conv2(x, skip2_out)\n",
    "        x = self.up_conv1(x, skip1_out)\n",
    "        x = self.conv_last(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "205d4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = smp.losses.DiceLoss(mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Epoch 1 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3213/3213 [23:41<00:00,  2.26it/s]  \n",
      "100%|██████████| 714/714 [01:03<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Epoch 1, Train_Loss: 0.08117051359870113, Val_Loss: 0.06600860997784037\n",
      "IoU Score : 0.691083550453186 f1 Score : 0.783936619758606 accuracy: 0.9798858165740967\n",
      "Dice score : 0.6890371441841125\n",
      "======Epoch 2 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3213/3213 [03:59<00:00, 13.41it/s]\n",
      "100%|██████████| 714/714 [00:21<00:00, 32.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Epoch 2, Train_Loss: 0.060935720659321686, Val_Loss: 0.06045425412211181\n",
      "IoU Score : 0.6386395692825317 f1 Score : 0.7022987604141235 accuracy: 0.9866619110107422\n",
      "Dice score : 0.758820652961731\n",
      "======Epoch 3 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3213/3213 [03:54<00:00, 13.72it/s]\n",
      "100%|██████████| 714/714 [00:21<00:00, 32.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Epoch 3, Train_Loss: 0.05605152063999282, Val_Loss: 0.05644596685037142\n",
      "IoU Score : 0.5840083360671997 f1 Score : 0.6759626269340515 accuracy: 0.9665888547897339\n",
      "Dice score : 0.6849937438964844\n",
      "======Epoch 4 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3213/3213 [03:56<00:00, 13.58it/s]\n",
      "100%|██████████| 714/714 [00:22<00:00, 31.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Epoch 4, Train_Loss: 0.05272753952535428, Val_Loss: 0.05474626704273062\n",
      "IoU Score : 0.7285196781158447 f1 Score : 0.8305956721305847 accuracy: 0.9810081124305725\n",
      "Dice score : 0.7461960911750793\n",
      "======Epoch 5 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3213/3213 [03:52<00:00, 13.84it/s]\n",
      "100%|██████████| 714/714 [00:16<00:00, 43.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train_Loss: 0.05032776708842492, Val_Loss: 0.055943417241562064\n",
      "IoU Score : 0.64598548412323 f1 Score : 0.7342007756233215 accuracy: 0.9750067591667175\n",
      "Dice score : 0.7546442151069641\n",
      "======Epoch 6 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3213/3213 [13:18<00:00,  4.02it/s]  \n",
      "100%|██████████| 714/714 [00:55<00:00, 12.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Epoch 6, Train_Loss: 0.04841133453116549, Val_Loss: 0.05370466501245938\n",
      "IoU Score : 0.6715273261070251 f1 Score : 0.7570958733558655 accuracy: 0.9710955023765564\n",
      "Dice score : 0.5735140442848206\n",
      "======Epoch 7 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3213/3213 [03:46<00:00, 14.20it/s]\n",
      "100%|██████████| 714/714 [00:17<00:00, 41.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Epoch 7, Train_Loss: 0.046943662899734444, Val_Loss: 0.05329543304647885\n",
      "IoU Score : 0.5736289024353027 f1 Score : 0.6641253232955933 accuracy: 0.9825053215026855\n",
      "Dice score : 0.7271260619163513\n",
      "======Epoch 8 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3213/3213 [03:43<00:00, 14.35it/s]\n",
      "100%|██████████| 714/714 [00:16<00:00, 42.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train_Loss: 0.045501011909283365, Val_Loss: 0.054262140771003664\n",
      "IoU Score : 0.7086567878723145 f1 Score : 0.7847345471382141 accuracy: 0.9798970222473145\n",
      "Dice score : 0.6892052888870239\n",
      "======Epoch 9 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3213/3213 [12:41<00:00,  4.22it/s]\n",
      "100%|██████████| 714/714 [00:51<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train_Loss: 0.044159279840569644, Val_Loss: 0.05468551014583944\n",
      "IoU Score : 0.7270853519439697 f1 Score : 0.8267183303833008 accuracy: 0.9808785915374756\n",
      "Dice score : 0.788135826587677\n",
      "======Epoch 10 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1658/3213 [05:49<05:27,  4.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4531/3862931109.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dawon/visionvenv/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dawon/visionvenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dawon/visionvenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dawon/visionvenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dawon/visionvenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model 초기화\n",
    "# model = UNet().to(device)\n",
    "\n",
    "# backbone resnet\n",
    "model = smp.Unet(\"resnet34\" , encoder_weights=\"imagenet\", activation=None, in_channels=3, classes=1)\n",
    "for name, p in model.named_parameters():\n",
    "    if \"encoder\" in name:\n",
    "        p.requires_grad = False\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# loss function과 optimizer 정의\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# validation\n",
    "best_validation_loss = 200.0\n",
    "\n",
    "# training loop\n",
    "for epoch in range(20):  # 10 에폭 동안 학습합니다.\n",
    "    print(f'======Epoch {epoch+1} =======')\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    val_loss = 0\n",
    "    for images, masks in tqdm(train_dataloader):\n",
    "        images = images.float().to(device)\n",
    "        masks = masks.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(val_dataloader):\n",
    "            images = images.float().to(device)\n",
    "            score_masks = masks.unsqueeze(1)\n",
    "            masks = masks.float().to(device)\n",
    "            outputs = model(images)\n",
    "            #score\n",
    "            score_masks = score_masks.to(device)\n",
    "            tp, fp, fn, tn = smp.metrics.get_stats(outputs, score_masks, mode='binary', threshold=0.35)\n",
    "            f1 = smp.metrics.f1_score(tp, fp, fn, tn)\n",
    "            iou = smp.metrics.iou_score(tp, fp, fn, tn)\n",
    "            accu = smp.metrics.accuracy(tp,fp, fn, tn)\n",
    "            dice_score = 1 - dice_loss(outputs, score_masks)\n",
    "            #loss\n",
    "            loss = criterion(outputs, masks.unsqueeze(1))\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    if best_validation_loss > val_loss/len(val_dataloader):\n",
    "        best_validation_loss = val_loss/len(val_dataloader)\n",
    "        torch.save(model, f'../best_model/best_model.pth')\n",
    "        print('Model saved!')\n",
    "    print(f'Epoch {epoch+1}, Train_Loss: {epoch_loss/len(train_dataloader)}, Val_Loss: {val_loss/len(val_dataloader)}')\n",
    "    print(f'IoU Score : {torch.mean(iou)} f1 Score : {torch.mean(f1)} accuracy: {torch.mean(accu)}')\n",
    "    print(f'Dice score : {dice_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('../best_model/best_model.pth')\n",
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full dataset size :  60640\n"
     ]
    }
   ],
   "source": [
    "test_dataset = SatelliteDataset(csv_file='../data/test.csv', transform=transform, infer=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3790/3790 [02:05<00:00, 30.09it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    result = []\n",
    "    for images in tqdm(test_dataloader):\n",
    "        images = images.float().to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        masks = torch.sigmoid(outputs).cpu().numpy()\n",
    "        masks = np.squeeze(masks, axis=1)\n",
    "        masks = (masks > 0.35).astype(np.uint8) # Threshold = 0.35\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            mask_rle = rle_encode(masks[i])\n",
    "            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n",
    "                result.append(-1)\n",
    "            else:\n",
    "                result.append(mask_rle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "submit['mask_rle'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('../submit/submit_UNET_bbrn34_224split.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visionvenv",
   "language": "python",
   "name": "visionvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
