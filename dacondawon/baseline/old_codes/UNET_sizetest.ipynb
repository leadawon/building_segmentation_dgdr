{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # nvidia-smi로 비어있는 gpu 확인하고 여기서 선택할것!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leadawon5/dawon/visionvenv/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 디코딩 함수\n",
    "def rle_decode(mask_rle, shape):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "        print(\"full dataset size : \",len(self.data))\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #img_path = self.data.iloc[idx, 1]    # default : ./train_img/TRAIN_0000.png\n",
    "        img_path = \"../data\"+self.data.iloc[idx, 1][1:]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "\n",
    "        mask_rle = self.data.iloc[idx, 2]\n",
    "        mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TV_SatelliteDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, is_train = True, TVcutter = int(7140 * 0.9)):\n",
    "        self.is_train = is_train\n",
    "        if self.is_train:\n",
    "            self.data = pd.read_csv(csv_file)[:TVcutter]\n",
    "        else:\n",
    "            self.data = pd.read_csv(csv_file)[TVcutter:]\n",
    "        self.transform = transform\n",
    "        print(\"full dataset size : \",len(self.data))\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #img_path = self.data.iloc[idx, 1]    # default : ./train_img/TRAIN_0000.png\n",
    "        img_path = \"../data\"+self.data.iloc[idx, 1][1:]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "     \n",
    "\n",
    "        mask_rle = self.data.iloc[idx, 2]\n",
    "        mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full dataset size :  6426\n",
      "full dataset size :  714\n"
     ]
    }
   ],
   "source": [
    "transform = A.Compose(\n",
    "    [   \n",
    "        A.Resize(512, 512),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = TV_SatelliteDataset(csv_file='../data/train.csv', transform=transform, is_train=True)\n",
    "val_dataset = TV_SatelliteDataset(csv_file='../data/train.csv', transform=transform, is_train=False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=True, num_workers=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "    \n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "        self.down_sample = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_out = self.double_conv(x)\n",
    "        down_out = self.down_sample(skip_out)\n",
    "        return (down_out, skip_out)\n",
    "\n",
    "    \n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, up_sample_mode):\n",
    "        super(UpBlock, self).__init__()\n",
    "        if up_sample_mode == 'conv_transpose':\n",
    "            self.up_sample = nn.ConvTranspose2d(in_channels-out_channels, in_channels-out_channels, kernel_size=2, stride=2)        \n",
    "        elif up_sample_mode == 'bilinear':\n",
    "            self.up_sample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported `up_sample_mode` (can take one of `conv_transpose` or `bilinear`)\")\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, down_input, skip_input):\n",
    "        x = self.up_sample(down_input)\n",
    "        x = torch.cat([x, skip_input], dim=1)\n",
    "        return self.double_conv(x)\n",
    "\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, out_classes=1, up_sample_mode='conv_transpose'): # out_class 1???\n",
    "        super(UNet, self).__init__()\n",
    "        self.up_sample_mode = up_sample_mode\n",
    "        # Downsampling Path\n",
    "        self.down_conv1 = DownBlock(3, 64)\n",
    "        self.down_conv2 = DownBlock(64, 128)\n",
    "        self.down_conv3 = DownBlock(128, 256)\n",
    "        self.down_conv4 = DownBlock(256, 512)\n",
    "        # Bottleneck\n",
    "        self.double_conv = DoubleConv(512, 1024)\n",
    "        # Upsampling Path\n",
    "        self.up_conv4 = UpBlock(512 + 1024, 512, self.up_sample_mode)\n",
    "        self.up_conv3 = UpBlock(256 + 512, 256, self.up_sample_mode)\n",
    "        self.up_conv2 = UpBlock(128 + 256, 128, self.up_sample_mode)\n",
    "        self.up_conv1 = UpBlock(128 + 64, 64, self.up_sample_mode)\n",
    "        # Final Convolution\n",
    "        self.conv_last = nn.Conv2d(64, out_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, skip1_out = self.down_conv1(x)\n",
    "        x, skip2_out = self.down_conv2(x)\n",
    "        x, skip3_out = self.down_conv3(x)\n",
    "        x, skip4_out = self.down_conv4(x)\n",
    "        x = self.double_conv(x)\n",
    "        x = self.up_conv4(x, skip4_out)\n",
    "        x = self.up_conv3(x, skip3_out)\n",
    "        x = self.up_conv2(x, skip2_out)\n",
    "        x = self.up_conv1(x, skip1_out)\n",
    "        x = self.conv_last(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "205d4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = smp.losses.DiceLoss(mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Epoch 1 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:19<00:00,  1.83it/s]\n",
      "100%|██████████| 179/179 [00:20<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Epoch 1, Train_Loss: 0.14676718836863392, Val_Loss: 0.10814845464166316\n",
      "IoU Score : 0.33127307891845703 f1 Score : 0.49728119373321533 accuracy: 0.9551582336425781\n",
      "Dice score : 0.49990957975387573\n",
      "======Epoch 2 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:16<00:00,  1.84it/s]\n",
      "100%|██████████| 179/179 [00:19<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Epoch 2, Train_Loss: 0.09190383313955804, Val_Loss: 0.08237803930302239\n",
      "IoU Score : 0.419137179851532 f1 Score : 0.5898749828338623 accuracy: 0.9619350433349609\n",
      "Dice score : 0.5434452295303345\n",
      "======Epoch 3 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:17<00:00,  1.84it/s]\n",
      "100%|██████████| 179/179 [00:20<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Epoch 3, Train_Loss: 0.07538537485108002, Val_Loss: 0.06866466967836439\n",
      "IoU Score : 0.6370255947113037 f1 Score : 0.7770673036575317 accuracy: 0.9826679229736328\n",
      "Dice score : 0.6358491778373718\n",
      "======Epoch 4 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:19<00:00,  1.83it/s]\n",
      "100%|██████████| 179/179 [00:21<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train_Loss: 0.0677338577945953, Val_Loss: 0.07668803466806531\n",
      "IoU Score : 0.6044784188270569 f1 Score : 0.7491178512573242 accuracy: 0.9781322479248047\n",
      "Dice score : 0.5728439092636108\n",
      "======Epoch 5 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:19<00:00,  1.83it/s]\n",
      "100%|██████████| 179/179 [00:20<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train_Loss: 0.06262512917199464, Val_Loss: 0.0703043865986876\n",
      "IoU Score : 0.655464768409729 f1 Score : 0.7884790897369385 accuracy: 0.9621238708496094\n",
      "Dice score : 0.7307112812995911\n",
      "======Epoch 6 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:18<00:00,  1.83it/s]\n",
      "100%|██████████| 179/179 [00:21<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Epoch 6, Train_Loss: 0.05825471236087864, Val_Loss: 0.05568333091890679\n",
      "IoU Score : 0.6519768238067627 f1 Score : 0.7880258560180664 accuracy: 0.9817485809326172\n",
      "Dice score : 0.6919800639152527\n",
      "======Epoch 7 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:21<00:00,  1.82it/s]\n",
      "100%|██████████| 179/179 [00:21<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train_Loss: 0.058331883264548, Val_Loss: 0.05696985794637123\n",
      "IoU Score : 0.6808085441589355 f1 Score : 0.8054350018501282 accuracy: 0.9908771514892578\n",
      "Dice score : 0.7616152167320251\n",
      "======Epoch 8 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:21<00:00,  1.82it/s]\n",
      "100%|██████████| 179/179 [00:21<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train_Loss: 0.053810512577531056, Val_Loss: 0.058776380671136205\n",
      "IoU Score : 0.6124429702758789 f1 Score : 0.7580742835998535 accuracy: 0.9758052825927734\n",
      "Dice score : 0.717006266117096\n",
      "======Epoch 9 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:19<00:00,  1.83it/s]\n",
      "100%|██████████| 179/179 [00:19<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Epoch 9, Train_Loss: 0.05173611725027214, Val_Loss: 0.055534315383967074\n",
      "IoU Score : 0.5649889707565308 f1 Score : 0.720674991607666 accuracy: 0.9864368438720703\n",
      "Dice score : 0.6148910522460938\n",
      "======Epoch 10 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:15<00:00,  1.84it/s]\n",
      "100%|██████████| 179/179 [00:19<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Epoch 10, Train_Loss: 0.05118556326227402, Val_Loss: 0.05219299188039822\n",
      "IoU Score : 0.5747938752174377 f1 Score : 0.7224687933921814 accuracy: 0.9811115264892578\n",
      "Dice score : 0.5862795114517212\n",
      "======Epoch 11 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:15<00:00,  1.85it/s]\n",
      "100%|██████████| 179/179 [00:19<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train_Loss: 0.04883462250399501, Val_Loss: 0.052601168442038854\n",
      "IoU Score : 0.7105284929275513 f1 Score : 0.8230758905410767 accuracy: 0.9702396392822266\n",
      "Dice score : 0.7485615611076355\n",
      "======Epoch 12 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:15<00:00,  1.85it/s]\n",
      "100%|██████████| 179/179 [00:19<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train_Loss: 0.04761953559931164, Val_Loss: 0.05543729061437719\n",
      "IoU Score : 0.7130371332168579 f1 Score : 0.8321274518966675 accuracy: 0.9840583801269531\n",
      "Dice score : 0.7244935035705566\n",
      "======Epoch 13 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:15<00:00,  1.85it/s]\n",
      "100%|██████████| 179/179 [00:19<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Epoch 13, Train_Loss: 0.045417211757537296, Val_Loss: 0.048505628356637236\n",
      "IoU Score : 0.6426796913146973 f1 Score : 0.7815055847167969 accuracy: 0.985809326171875\n",
      "Dice score : 0.7084813117980957\n",
      "======Epoch 14 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:16<00:00,  1.84it/s]\n",
      "100%|██████████| 179/179 [00:19<00:00,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train_Loss: 0.044362119503263665, Val_Loss: 0.05009851219684052\n",
      "IoU Score : 0.6556451916694641 f1 Score : 0.7914422750473022 accuracy: 0.9615077972412109\n",
      "Dice score : 0.7487612962722778\n",
      "======Epoch 15 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:15<00:00,  1.85it/s]\n",
      "100%|██████████| 179/179 [00:19<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Epoch 15, Train_Loss: 0.04379776966137191, Val_Loss: 0.04725046656172535\n",
      "IoU Score : 0.7735642194747925 f1 Score : 0.8722047209739685 accuracy: 0.9919261932373047\n",
      "Dice score : 0.8096641898155212\n",
      "======Epoch 16 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:15<00:00,  1.85it/s]\n",
      "100%|██████████| 179/179 [00:20<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train_Loss: 0.04222162887083357, Val_Loss: 0.04850697085552708\n",
      "IoU Score : 0.7742580771446228 f1 Score : 0.8726288080215454 accuracy: 0.9865550994873047\n",
      "Dice score : 0.817384660243988\n",
      "======Epoch 17 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:15<00:00,  1.84it/s]\n",
      "100%|██████████| 179/179 [00:19<00:00,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train_Loss: 0.04151135603132755, Val_Loss: 0.04891551254764615\n",
      "IoU Score : 0.7191575765609741 f1 Score : 0.8359261751174927 accuracy: 0.9917488098144531\n",
      "Dice score : 0.7836812734603882\n",
      "======Epoch 18 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:15<00:00,  1.84it/s]\n",
      "100%|██████████| 179/179 [00:19<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Epoch 18, Train_Loss: 0.04009089863683046, Val_Loss: 0.04633677347079335\n",
      "IoU Score : 0.6566190719604492 f1 Score : 0.7900345325469971 accuracy: 0.9541130065917969\n",
      "Dice score : 0.7520853877067566\n",
      "======Epoch 19 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:15<00:00,  1.84it/s]\n",
      "100%|██████████| 179/179 [00:19<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Epoch 19, Train_Loss: 0.03942373742706221, Val_Loss: 0.046113590621415464\n",
      "IoU Score : 0.774950385093689 f1 Score : 0.8668789863586426 accuracy: 0.9937057495117188\n",
      "Dice score : 0.8104443550109863\n",
      "======Epoch 20 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [07:17<00:00,  1.84it/s]\n",
      "100%|██████████| 179/179 [00:19<00:00,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train_Loss: 0.03844672383332801, Val_Loss: 0.04852697608066338\n",
      "IoU Score : 0.6373270153999329 f1 Score : 0.7769858837127686 accuracy: 0.9873638153076172\n",
      "Dice score : 0.7066503763198853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model 초기화\n",
    "model = UNet().to(device)\n",
    "\n",
    "# backbone resnet\n",
    "# model = smp.Unet(\"resnet34\" , encoder_weights=\"imagenet\", activation=None, in_channels=3, classes=1)\n",
    "# for name, p in model.named_parameters():\n",
    "#     if \"encoder\" in name:\n",
    "#         p.requires_grad = False\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# loss function과 optimizer 정의\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# validation\n",
    "best_validation_loss = 200.0\n",
    "\n",
    "# training loop\n",
    "for epoch in range(20):  # 10 에폭 동안 학습합니다.\n",
    "    print(f'======Epoch {epoch+1} =======')\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    val_loss = 0\n",
    "    for images, masks in tqdm(train_dataloader):\n",
    "        images = images.float().to(device)\n",
    "        masks = masks.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(val_dataloader):\n",
    "            images = images.float().to(device)\n",
    "            score_masks = masks.unsqueeze(1)\n",
    "            masks = masks.float().to(device)\n",
    "            outputs = model(images)\n",
    "            #score\n",
    "            score_masks = score_masks.to(device)\n",
    "            tp, fp, fn, tn = smp.metrics.get_stats(outputs, score_masks, mode='binary', threshold=0.35)\n",
    "            f1 = smp.metrics.f1_score(tp, fp, fn, tn)\n",
    "            iou = smp.metrics.iou_score(tp, fp, fn, tn)\n",
    "            accu = smp.metrics.accuracy(tp,fp, fn, tn)\n",
    "            dice_score = 1 - dice_loss(outputs, score_masks)\n",
    "            #loss\n",
    "            loss = criterion(outputs, masks.unsqueeze(1))\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    if best_validation_loss > val_loss/len(val_dataloader):\n",
    "        best_validation_loss = val_loss/len(val_dataloader)\n",
    "        torch.save(model, f'../best_model/best_model.pth')\n",
    "        print('Model saved!')\n",
    "    print(f'Epoch {epoch+1}, Train_Loss: {epoch_loss/len(train_dataloader)}, Val_Loss: {val_loss/len(val_dataloader)}')\n",
    "    print(f'IoU Score : {torch.mean(iou)} f1 Score : {torch.mean(f1)} accuracy: {torch.mean(accu)}')\n",
    "    print(f'Dice score : {dice_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (down_conv1): DownBlock(\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down_sample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (down_conv2): DownBlock(\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down_sample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (down_conv3): DownBlock(\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down_sample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (down_conv4): DownBlock(\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down_sample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (double_conv): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up_conv4): UpBlock(\n",
       "    (up_sample): ConvTranspose2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_conv3): UpBlock(\n",
       "    (up_sample): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_conv2): UpBlock(\n",
       "    (up_sample): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_conv1): UpBlock(\n",
       "    (up_sample): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_last): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('../best_model/best_model.pth')\n",
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full dataset size :  60640\n"
     ]
    }
   ],
   "source": [
    "test_dataset = SatelliteDataset(csv_file='../data/test.csv', transform=transform, infer=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3790 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3790/3790 [23:26<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    result = []\n",
    "    for images in tqdm(test_dataloader):\n",
    "        images = images.float().to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        masks = torch.sigmoid(outputs).cpu().numpy()\n",
    "        masks = np.squeeze(masks, axis=1)\n",
    "        masks = (masks > 0.35).astype(np.uint8) # Threshold = 0.35\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            mask_rle = rle_encode(masks[i])\n",
    "            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n",
    "                result.append(-1)\n",
    "            else:\n",
    "                result.append(mask_rle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../data/sample_submission.csv')\n",
    "submit['mask_rle'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('../submit/submit_UNETwithBN512size.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visionvenv",
   "language": "python",
   "name": "visionvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
