{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(train_dataloader)\n",
    "# images, masks = dataiter.next()\n",
    "\n",
    "# # 데이터로더 증강데이터 시각화\n",
    "# fig, axes = plt.subplots(2, 8, figsize=(12, 6))\n",
    "\n",
    "# for i in range(8):\n",
    "#     axes[0, i].imshow(images[i].permute(1, 2, 0))\n",
    "#     axes[0, i].set_title(f\"TrainSample\\n{images[i].shape[1]} x {images[i].shape[2]}\")\n",
    "\n",
    "#     axes[1, i].imshow(masks[i].squeeze(), cmap='gray')\n",
    "#     axes[1, i].set_title(f\"Mask\\n{masks[i].shape[0]} x {masks[i].shape[1]}\")\n",
    "\n",
    "#     #격자 제거\n",
    "#     axes[0, i].axis('off')\n",
    "#     axes[1, i].axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output \n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_idx(path):\n",
    "    img_path = path\n",
    "    image = cv2.imread(img_path)\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "    # 이미지 분할\n",
    "    patches = split_image(image, 224, 224)\n",
    "\n",
    "    return patches\n",
    "\n",
    "def split_image(image, patch_size, stride):\n",
    "        patches = []\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        \n",
    "        for i in range(0, h-patch_size+1, stride):\n",
    "            for j in range(0, w-patch_size+1, stride):\n",
    "                if i+patch_size > h or j+patch_size > w:\n",
    "                     continue\n",
    "                patch = image[i:i+patch_size, j:j+patch_size]\n",
    "                patches.append(patch)\n",
    "        return patches\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "temp = get_list_idx(\"./ggp3.png\")\n",
    "for j,v in enumerate(temp):\n",
    "    cv2.imwrite(f\"./split_custom/ggp3_img/{j}.png\",v)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 ~ 7139 _ 0~15 . png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsvenv",
   "language": "python",
   "name": "bsvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
